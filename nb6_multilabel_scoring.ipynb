{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc8efdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sdir = './scrub/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db050951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'multilabel_v1.csv')[['content', 'target']].sample(frac=1)\n",
    "data['target'] = data['target'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6722c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cls_1     439.0\n",
       "cls_2     212.0\n",
       "cls_3     249.0\n",
       "cls_4     624.0\n",
       "cls_5     185.0\n",
       "cls_6     289.0\n",
       "cls_7     417.0\n",
       "cls_8     529.0\n",
       "cls_9     470.0\n",
       "cls_10    252.0\n",
       "cls_11    857.0\n",
       "cls_12    121.0\n",
       "cls_13    253.0\n",
       "cls_14    148.0\n",
       "cls_15    157.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame(data['target'].values.tolist(), columns = [f'cls_{i+1}' for i in range(15)])\n",
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6b711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7206a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '—Ü–µ–Ω–∞',\n",
       " 1: '–æ–ø–ª–∞—Ç–∞',\n",
       " 2: '–ª–æ—è–ª—å–Ω–æ—Å—Ç—å',\n",
       " 3: '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è/–∫–æ–¥—ã',\n",
       " 4: '–∫—É–ø–æ–Ω—ã',\n",
       " 5: '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ',\n",
       " 6: 'uxui',\n",
       " 7: '–≥–ª—é–∫–∏_–±–∞–≥–∏_—Ç–æ—Ä–º–æ–∑–∞',\n",
       " 8: '–¥—Ä—É–≥–æ–µ',\n",
       " 9: '–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ',\n",
       " 10: '–¥–æ—Å—Ç–∞–≤–∫–∞_–æ–±—â–µ–µ',\n",
       " 11: '–∞–∫–∫–∞—É–Ω—Ç',\n",
       " 12: '–¥–æ–ª–≥–æ–µ_–æ–∂–∏–¥–∞–Ω–∏–µ_–¥–æ—Å—Ç–∞–≤–∫–∏',\n",
       " 13: '—Å–æ–∑–¥–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞',\n",
       " 14: '–Ω–µ_–≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è_–¥–µ–Ω—å–≥–∏_–æ—Ç–º–µ–Ω–µ–Ω–Ω–æ–≥–æ_–∑–∞–∫–∞–∑–∞'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'—Ü–µ–Ω–∞': 0,\n",
       " '–æ–ø–ª–∞—Ç–∞': 1,\n",
       " '–ª–æ—è–ª—å–Ω–æ—Å—Ç—å': 2,\n",
       " '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è/–∫–æ–¥—ã': 3,\n",
       " '–∫—É–ø–æ–Ω—ã': 4,\n",
       " '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ': 5,\n",
       " 'uxui': 6,\n",
       " '–≥–ª—é–∫–∏_–±–∞–≥–∏_—Ç–æ—Ä–º–æ–∑–∞': 7,\n",
       " '–¥—Ä—É–≥–æ–µ': 8,\n",
       " '–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ': 9,\n",
       " '–¥–æ—Å—Ç–∞–≤–∫–∞_–æ–±—â–µ–µ': 10,\n",
       " '–∞–∫–∫–∞—É–Ω—Ç': 11,\n",
       " '–¥–æ–ª–≥–æ–µ_–æ–∂–∏–¥–∞–Ω–∏–µ_–¥–æ—Å—Ç–∞–≤–∫–∏': 12,\n",
       " '—Å–æ–∑–¥–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞': 13,\n",
       " '–Ω–µ_–≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è_–¥–µ–Ω—å–≥–∏_–æ—Ç–º–µ–Ω–µ–Ω–Ω–æ–≥–æ_–∑–∞–∫–∞–∑–∞': 14}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_excel(f'{sdir}t4m_2022_05_05__21_59.xlsx')\n",
    "cnames = list(set(t['class_name'].values))\n",
    "idx2cls = {i:v for i,v in enumerate(cnames)}\n",
    "cls2idx = {v:i for i,v in enumerate(cnames)}\n",
    "display(idx2cls)\n",
    "cls2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b63c2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset,DatasetDict, load_metric\n",
    "\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b06f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': '–£–∂–∞—Å–Ω–æ –Ω–µ—É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " 'label': [0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " '__index_level_0__': 895}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['content', 'target']].set_axis(['headline', 'label'], axis=1)\n",
    "data=Dataset.from_pandas(data)\n",
    "\n",
    "# 80% train, 20% test + validation\n",
    "train_testvalid = data.train_test_split(test_size=0.3,seed=15)\n",
    "\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5,seed=15)\n",
    "\n",
    "# gather everything to have a single DatasetDict\n",
    "data = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train'],\n",
    "                   })\n",
    "\n",
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0896541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/distilrubert-small-cased-conversational were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/rvsl/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/var/folders/_r/mpnhfz9d4nv5tm_1d27p_36w0000gn/T/ipykernel_23449/3284622978.py:84: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca5bf122b4431ca2292f17df025876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ff1443ec24241b996930df3337818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5105042016806722}\n",
      "{'accuracy': 0.5336134453781513}\n",
      "{'accuracy': 0.5378151260504201}\n",
      "{'accuracy': 0.5441176470588235}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "seq_len = 512\n",
    "n_classes = len(idx2cls.items())\n",
    "out_features=768\n",
    "\n",
    "# device = torch.device('mps')\n",
    "# couldn't make distilbert uncased work on apple silicon, so i took random bert trained on news.\n",
    "# also found bert trained on rotten tomatoes, but it was big and slow\n",
    "checkpoint = 'cointegrated/rubert-tiny2'\n",
    "# checkpoint = 'cointegrated/rubert-tiny'\n",
    "checkpoint = 'DeepPavlov/distilrubert-small-cased-conversational'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.model_max_len=seq_len\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"headline\"], truncation=True,max_length=seq_len)\n",
    "\n",
    "tokenized_dataset = data.map(tokenize, batched=True)\n",
    "\n",
    "tokenized_dataset.set_format(\"torch\",columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels, out_features=768):\n",
    "        super(CustomModel,self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        #Load Model with given checkpoint and extract its body\n",
    "        self.model = AutoModel.from_pretrained(checkpoint,\n",
    "                                                config=AutoConfig.from_pretrained(checkpoint, \n",
    "                                                                                 output_attentions=True,\n",
    "                                                                                 output_hidden_states=True))\n",
    "        \n",
    "        self.out_features = out_features#model.encoder.layer[1].output.dense.out_features\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.out_features, num_labels) # load and initialize weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "        #Extract outputs from the body\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        #Add custom layers\n",
    "        sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
    "        \n",
    "        logits = self.classifier(sequence_output[:,0,:].view(-1,self.out_features)) # calculate losses\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.float().view(-1, self.num_labels))\n",
    "\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = CustomModel(checkpoint=checkpoint, num_labels=n_classes, out_features=out_features).to(device)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"], shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"valid\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        targets = torch.argmax(batch[\"labels\"], dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=targets)\n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    print(metric.compute())\n",
    "\n",
    "\n",
    "torch.save(model, 'bert_model_v1.pt')\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    targets = torch.argmax(batch[\"labels\"], dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=targets)\n",
    "\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e88cd6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.5873077586317496}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.58      0.69        55\n",
      "           1       0.85      0.63      0.72        27\n",
      "           2       0.94      0.45      0.61        33\n",
      "           3       0.52      0.41      0.46        68\n",
      "           4       0.83      0.65      0.73        31\n",
      "           5       0.75      0.59      0.66        46\n",
      "           6       0.57      0.54      0.55        52\n",
      "           7       0.47      0.45      0.46        49\n",
      "           8       0.57      0.79      0.67        34\n",
      "           9       1.00      0.39      0.57        33\n",
      "          10       0.13      0.60      0.21        15\n",
      "          11       0.33      0.18      0.24        11\n",
      "          12       0.13      0.80      0.23         5\n",
      "          13       0.45      0.83      0.59         6\n",
      "          14       0.62      0.91      0.74        11\n",
      "\n",
      "    accuracy                           0.54       476\n",
      "   macro avg       0.60      0.59      0.54       476\n",
      "weighted avg       0.67      0.54      0.57       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"recall\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "preds = []\n",
    "labs = []\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    targets = torch.argmax(batch[\"labels\"], dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=targets)\n",
    "    \n",
    "    preds += list(torch.argmax(logits, dim=-1).detach().cpu().numpy())\n",
    "    labs += list(torch.argmax(batch[\"labels\"], dim=-1).detach().cpu().numpy())\n",
    "\n",
    "print(metric.compute(average='macro'))\n",
    "\n",
    "test = tokenized_dataset[\"test\"].to_pandas()\n",
    "test['preds'] = preds\n",
    "test['true'] = labs\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test['true'], test['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa46cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = load_metric(\"recall\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "preds = []\n",
    "labs = []\n",
    "thresh = 0.85\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    l = torch.sigmoid(logits).cpu().numpy().tolist()\n",
    "    \n",
    "    predictions = [[1 if i > thresh else 0 for i in j] for j in l]\n",
    "#     break\n",
    "\n",
    "#     predictions = torch.argmax(logits, dim=-1)\n",
    "#     targets = torch.argmax(batch[\"labels\"], dim=-1)\n",
    "    targets = batch[\"labels\"].cpu().numpy().tolist()\n",
    "    preds.extend(predictions)\n",
    "    labs.extend(targets)\n",
    "    \n",
    "    \n",
    "#     preds += list(torch.argmax(logits, dim=-1).detach().cpu().numpy())\n",
    "#     labs += list(torch.argmax(batch[\"labels\"], dim=-1).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "test = tokenized_dataset[\"test\"].to_pandas()\n",
    "test['preds'] = preds\n",
    "test['true'] = labs\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# print(classification_report(test['true'], test['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e84b946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>label</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>preds</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°–∞–º–æ–µ —É–∂–∞—Å–Ω–æ–µ —á—Ç–æ —Ç–æ–ª—å–∫–æ –±—ã–ª–æ, –Ω–µ —Å—Ç–æ–∏—Ç —Å–≤–æ–∏—Ö ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1896</td>\n",
       "      <td>[101, 5419, 34423, 825, 1031, 1035, 128, 802, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ù–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>2044</td>\n",
       "      <td>[101, 1067, 3161, 41662, 814, 3679, 2269, 8087...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–°–∞–º–æ–µ —É–±–æ–≥–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ—è —è –≤–∏–¥–µ–ª. –†–∞–∑ ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2410</td>\n",
       "      <td>[101, 5419, 80236, 17589, 128, 1808, 359, 358,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù–∞–≤—è–∑—ã–≤–∞—é—Ç –æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ –∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ü–µ–Ω–∫—É, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1493</td>\n",
       "      <td>[101, 16528, 10324, 1466, 7529, 18358, 322, 57...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É–∂–∞—Å–Ω–æ–µ, –≤—Å–µ –ª–∞–≥–∞–µ—Ç, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–∏...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>778</td>\n",
       "      <td>[101, 85227, 34423, 128, 888, 12598, 303, 798,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  –°–∞–º–æ–µ —É–∂–∞—Å–Ω–æ–µ —á—Ç–æ —Ç–æ–ª—å–∫–æ –±—ã–ª–æ, –Ω–µ —Å—Ç–æ–∏—Ç —Å–≤–æ–∏—Ö ...   \n",
       "1  –ù–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å...   \n",
       "2  –°–∞–º–æ–µ —É–±–æ–≥–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ—è —è –≤–∏–¥–µ–ª. –†–∞–∑ ...   \n",
       "3  –ù–∞–≤—è–∑—ã–≤–∞—é—Ç –æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ –∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ü–µ–Ω–∫—É, ...   \n",
       "4  –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É–∂–∞—Å–Ω–æ–µ, –≤—Å–µ –ª–∞–≥–∞–µ—Ç, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–∏...   \n",
       "\n",
       "                                               label  __index_level_0__  \\\n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...               1896   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...               2044   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...               2410   \n",
       "3  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...               1493   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                778   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 5419, 34423, 825, 1031, 1035, 128, 802, ...   \n",
       "1  [101, 1067, 3161, 41662, 814, 3679, 2269, 8087...   \n",
       "2  [101, 5419, 80236, 17589, 128, 1808, 359, 358,...   \n",
       "3  [101, 16528, 10324, 1466, 7529, 18358, 322, 57...   \n",
       "4  [101, 85227, 34423, 128, 888, 12598, 303, 798,...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                           preds  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "4  [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]   \n",
       "\n",
       "                                                true  \n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b5d5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "true0 = test['true'].values[0]\n",
    "pred0 = test['preds'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f16f0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_recall(true0, pred0):\n",
    "    r = 0\n",
    "    for i, v in enumerate(true0):\n",
    "        if pred0[i] == v : r += 1\n",
    "        else: r -+ 1\n",
    "    return r/len(true0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e997f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100840336134455"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for true0, pred0 in zip(test['true'].values, test['preds'].values):\n",
    "    res.append(pos_recall(true0, pred0))\n",
    "np.mean(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe26557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
